{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fonctions de base"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import numpy as np\n",
      "import random\n",
      "import pylab\n",
      "import time\n",
      "\n",
      "def minkowski_vec(x1,x2,p=2.0):\n",
      "    diff = (np.abs(x1-x2)**p).sum()**(1.0/p)\n",
      "    return diff\n",
      "\n",
      "def minkowski_mat(x,Y,p=2.0):\n",
      "    dist = (np.abs(x-Y)**p).sum(1)**(1.0/p)\n",
      "    return dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La fonction gaussienne_vec retourne, en un point x, un noyau Gaussien sph\u00e9rique centr\u00e9 en \u03bc et de variance \u03c32."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gaussienne_vec(x1,x2,variance):\n",
      "    resultat = exp((minkowski_vec(x1,x2)**2)/((-2)*variance))\n",
      "    return resultat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La fonction gaussienne_mat retourne, pour une matrice X, un noyau Gaussien sph\u00e9rique centr\u00e9 en \u03bc et de variance \u03c32 pour tous les points de la matrice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gaussienne_mat(X,x,variance):\n",
      "    resultat = exp((minkowski_mat(X,x)**2)/((-2)*variance))\n",
      "    return resultat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La fonction regression effectue la r\u00e9gression multiple de Parzen et retourne l'esp\u00e9rance de la classe du point x."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def regression(X,x,variance,Y):\n",
      "    w = gaussienne_mat(X,x,variance)\n",
      "    resultat = (1/(w.sum()))*(w*np.transpose(Y)).sum(1)\n",
      "    return resultat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification multiclasse de Parzen"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La classe parzen impl\u00e9mente l'algorithme de classification multiclasse de Parzen. L'algorithme retourne une matrice les_comptes contenant dans chaque rang\u00e9e la probabilit\u00e9 qu'un point dans l'ensemble de test corresponde \u00e0 chacune des classes de l'ensemble d'entra\u00eenement. Pour ce faire, la fonction regression est appel\u00e9e avec comme arguments respectifs : la matrice des points de l'ensemble d'entra\u00eenement, le point \u00e0 \u00e9tudier dans l'ensemble de test, le sigma (donn\u00e9 par l'utilisateur) au carr\u00e9, et une matrice one hot repr\u00e9sentant la classe de chaque point de l'ensemble d'entra\u00eenement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class parzen:\n",
      "    def __init__(self,n_classes,var,reg_func=regression):\n",
      "        self.n_classes = n_classes\n",
      "        self.reg_func = reg_func\n",
      "        self.var = var\n",
      "\n",
      "    def train(self, train_data):\n",
      "        self.train_data = train_data\n",
      "        num_train = train_data.shape[0]\n",
      "        self.one_hot = np.zeros((num_train,self.n_classes))\n",
      "        classes = train_data[:,-1]\n",
      "\n",
      "        for i in range(num_train):\n",
      "            pass\n",
      "            no_classe = classes[i]\n",
      "            self.one_hot[i,(no_classe-1)] = 1\n",
      "\n",
      "    def compute_predictions(self, test_data):\n",
      "        num_test = test_data.shape[0]\n",
      "        les_comptes = np.ones((num_test,self.n_classes))\n",
      "\n",
      "        for (i,ex) in enumerate(test_data):\n",
      "            pass\n",
      "            reg = self.reg_func(self.train_data[:,:-1],ex,self.var,self.one_hot)\n",
      "            les_comptes[i,:] = reg\n",
      "\n",
      "        return les_comptes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On d\u00e9termine ici le sigma d\u00e9sir\u00e9."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sigma = 0.25"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fonctions d'affichage graphique"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def conf_matrix(etiquettesTest, etiquettesPred):\n",
      "\n",
      "\tn_classes = max(etiquettesTest)\n",
      "\tmatrix = np.zeros((n_classes,n_classes))\n",
      "\n",
      "\tfor (test,pred) in zip(etiquettesTest, etiquettesPred):\n",
      "\t\tmatrix[test-1,pred-1] += 1\n",
      "\n",
      "\treturn matrix\n",
      "\n",
      "# fonction plot\n",
      "def gridplot(classifieur,train,test,n_points=50):\n",
      "\n",
      "    train_test = np.vstack((train,test))\n",
      "    (min_x1,max_x1) = (min(train_test[:,0]),max(train_test[:,0]))\n",
      "    (min_x2,max_x2) = (min(train_test[:,1]),max(train_test[:,1]))\n",
      "\n",
      "    xgrid = np.linspace(min_x1,max_x1,num=n_points)\n",
      "    ygrid = np.linspace(min_x2,max_x2,num=n_points)\n",
      "\n",
      "\t# calcule le produit cartesien entre deux listes\n",
      "    # et met les resultats dans un array\n",
      "    thegrid = np.array(combine(xgrid,ygrid))\n",
      "\n",
      "    les_comptes = classifieur.compute_predictions(thegrid)\n",
      "    classesPred = np.argmax(les_comptes,axis=1)+1\n",
      "\n",
      "    # La grille\n",
      "    # Pour que la grille soit plus jolie\n",
      "    #props = dict( alpha=0.3, edgecolors='none' )\n",
      "    pylab.scatter(thegrid[:,0],thegrid[:,1],c = classesPred, s=50, edgecolors='none')\n",
      "\t# Les points d'entrainment\n",
      "    pylab.scatter(train[:,0], train[:,1], c = train[:,-1], marker = 'v', s=150)\n",
      "    # Les points de test\n",
      "    pylab.scatter(test[:,0], test[:,1], c = test[:,-1], marker = 's', s=150)\n",
      "\n",
      "    ## Un petit hack, parce que la fonctionalite manque a pylab...\n",
      "    h1 = pylab.plot([min_x1], [min_x2], marker='o', c = 'w',ms=5)\n",
      "    h2 = pylab.plot([min_x1], [min_x2], marker='v', c = 'w',ms=5)\n",
      "    h3 = pylab.plot([min_x1], [min_x2], marker='s', c = 'w',ms=5)\n",
      "    handles = [h1,h2,h3]\n",
      "    ## fin du hack\n",
      "\n",
      "    labels = ['grille','train','test']\n",
      "    pylab.legend(handles,labels)\n",
      "\n",
      "    pylab.axis('equal')\n",
      "    pylab.show()\n",
      "\n",
      "## http://code.activestate.com/recipes/302478/\n",
      "def combine(*seqin):\n",
      "    '''returns a list of all combinations of argument sequences.\n",
      "for example: combine((1,2),(3,4)) returns\n",
      "[[1, 3], [1, 4], [2, 3], [2, 4]]'''\n",
      "    def rloop(seqin,listout,comb):\n",
      "        '''recursive looping function'''\n",
      "        if seqin:                       # any more sequences to process?\n",
      "            for item in seqin[0]:\n",
      "                newcomb=comb+[item]     # add next item to current comb\n",
      "                # call rloop w/ rem seqs, newcomb\n",
      "                rloop(seqin[1:],listout,newcomb)\n",
      "        else:                           # processing last sequence\n",
      "            listout.append(comb)        # comb finished, add to list\n",
      "    listout=[]                      # listout initialization\n",
      "    rloop(seqin,listout,[])         # start recursive process\n",
      "    return listout\n",
      "\n",
      "# charger iris\n",
      "iris = np.loadtxt('iris.txt')\n",
      "data = iris\n",
      "\n",
      "# Nombre de classes\n",
      "n_classes = 3\n",
      "# Nombre de points d'entrainement\n",
      "n_train = 100\n",
      "\n",
      "# Les colonnes (traits/caracteristiques) sur lesqueles on va entrainer notre modele\n",
      "# Pour que gridplot fonctionne, len(train_cols) devrait etre 2\n",
      "train_cols = [0,1]\n",
      "# L'indice de la colonne contenant les etiquettes\n",
      "target_ind = [data.shape[1] - 1]\n",
      "\n",
      "# Commenter pour avoir des resultats non-deterministes\n",
      "random.seed(3395)\n",
      "# Determiner au hasard des indices pour les exemples d'entrainement et de test\n",
      "inds = range(data.shape[0])\n",
      "random.shuffle(inds)\n",
      "train_inds = inds[:n_train]\n",
      "test_inds = inds[n_train:]\n",
      "\n",
      "# Separer les donnees dans les deux ensembles\n",
      "train_set = data[train_inds,:]\n",
      "train_set = train_set[:,train_cols + target_ind]\n",
      "test_set = data[test_inds,:]\n",
      "test_set = test_set[:,train_cols + target_ind]\n",
      "\n",
      "# Separarer l'ensemble de test dans les entrees et les etiquettes\n",
      "test_inputs = test_set[:,:-1]\n",
      "test_labels = test_set[:,-1]\n",
      "\n",
      "# Taille de sigma dans Parzen\n",
      "print \"On va entrainer un algo de Parzen avec un sigma de \",sigma, \"sur \",n_train, \" exemples d'entrainement\"\n",
      "\n",
      "# Creer le classifieur\n",
      "model = parzen(n_classes,sigma**2,reg_func=regression)\n",
      "# L'entrainer\n",
      "model.train(train_set)\n",
      "# Obtenir ses predictions\n",
      "t1 = time.clock()\n",
      "les_comptes = model.compute_predictions(test_inputs)\n",
      "t2 = time.clock()\n",
      "print 'Ca nous a pris ', t2-t1, ' secondes pour calculer les predictions sur ', test_inputs.shape[0],' points de test'\n",
      "\n",
      "# Vote majoritaire (+1 puisque nos classes sont de 1 a n)\n",
      "classes_pred = np.argmax(les_comptes,axis=1)+1\n",
      "\n",
      "# Faire les tests\n",
      "# Matrice de confusion\n",
      "confmat = conf_matrix(test_labels, classes_pred)\n",
      "print 'La matrice de confusion est:'\n",
      "print confmat\n",
      "\n",
      "# Erreur de test\n",
      "sum_preds = np.sum(confmat)\n",
      "sum_correct = np.sum(np.diag(confmat))\n",
      "print \"L'erreur de test est de \", 100*(1.0 - (float(sum_correct) / sum_preds)),\"%\"\n",
      "\n",
      "# Taille de la grille = grid_size x grid_size\n",
      "grid_size = 200\n",
      "\n",
      "if len(train_cols) == 2:\n",
      "    # Surface de decision\n",
      "    t1 = time.clock()\n",
      "    gridplot(model,train_set,test_set,n_points = grid_size)\n",
      "    t2 = time.clock()\n",
      "    print 'Ca nous a pris ', t2-t1, ' secondes pour calculer les predictions sur ', grid_size * grid_size, ' points de la grille'\n",
      "    filename = 'grille_' + '_sigma=' + str(sigma) + '_c1=' + str(train_cols[0]) + '_c2=' + str(train_cols[1])+'.png'\n",
      "    print 'On va sauvegarder la figure dans ', filename\n",
      "    pylab.savefig(filename,format='png')\n",
      "else:\n",
      "    print 'Trop de dimensions (', len(train_cols),') pour pouvoir afficher la surface de decision'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}